{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def aggregate_raster(input_path, output_path, agg_factor, agg_func=np.sum):\n",
    "    # Open the source raster\n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Read the source raster data\n",
    "        data = src.read(1)\n",
    "        # Get the transform and metadata\n",
    "        transform = src.transform\n",
    "        meta = src.meta.copy()\n",
    "        \n",
    "        # Define the new shape after aggregation\n",
    "        new_height = data.shape[0] // agg_factor\n",
    "        new_width = data.shape[1] // agg_factor\n",
    "        \n",
    "        # Initialize an array to hold the aggregated data\n",
    "        agg_data = np.zeros((new_height, new_width), dtype=data.dtype)\n",
    "        \n",
    "        # Perform the aggregation\n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "                # Define the window\n",
    "                window = data[i*agg_factor:(i+1)*agg_factor, j*agg_factor:(j+1)*agg_factor]\n",
    "                # Apply the aggregation function\n",
    "                agg_data[i, j] = agg_func(window)\n",
    "        \n",
    "        # Update the transform for the new raster\n",
    "        new_transform = transform * transform.scale((src.width / agg_data.shape[1]), (src.height / agg_data.shape[0]))\n",
    "        \n",
    "        # Update the metadata\n",
    "        meta.update({\n",
    "            'height': new_height,\n",
    "            'width': new_width,\n",
    "            'transform': new_transform\n",
    "        })\n",
    "        \n",
    "        # Write the aggregated data to a new file\n",
    "        with rasterio.open(output_path, 'w', **meta) as dest:\n",
    "            dest.write(agg_data, 1)\n",
    "\n",
    "# Example usage\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "infolder = os.path.join(outputFolder, 'BA_100m') # Burnt area where pixel values is 1 when there is a wildfire\n",
    "outfolder = os.path.join(outputFolder, 'BA_1km_vrasterio')\n",
    "os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "input_raster = os.path.join(outputFolder, 'BA_100m', 'FIREID_2001.tif') \n",
    "output_raster = os.path.join(outputFolder, 'BA_1km_vrasterio', 'BA_1km_2001.tif')\n",
    "aggregation_factor = 10  # Change this to your desired aggregation factor\n",
    "aggregate_raster(input_raster, output_raster, aggregation_factor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "Q:\\UserTemp\\ubach\\AppData\\Local\\Temp\\4\\ipykernel_173084\\3466570486.py:2: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LogNorm\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject\n",
    "from rasterio.windows import Window, transform as rio_window_transform\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import box\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.delayed import delayed\n",
    "\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "import seaborn as sns\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_and_clip_to_target(input_raster_path, target_raster_path, output_raster_path, compression, dtype):\n",
    "    \"\"\"\n",
    "    Rescale a raster to match the resolution and clip it to the extent of another raster.\n",
    "\n",
    "    Parameters:\n",
    "    - input_raster_path: str, path to the input raster file (e.g., 'path/to/input_raster.tif')\n",
    "    - target_raster_path: str, path to the target raster file (e.g., 'path/to/target_raster.tif')\n",
    "    - output_raster_path: str, path to the output raster file (e.g., 'path/to/output_raster.tif')\n",
    "    - compression: str, compression type (e.g., 'zstd', 'deflate', 'lwz')\n",
    "    - dtype: str, output data type (e.g., 'int16')\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(target_raster_path) as target_src:\n",
    "        # Get the extent and resolution of the target raster\n",
    "        target_extent = target_src.bounds\n",
    "        target_resolution = target_src.res[0]  # Assuming square pixels\n",
    "    \n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        # Ensure the data type is the same as the target\n",
    "        if src.dtypes[0] != dtype:\n",
    "            raise ValueError(f\"Input raster is not of type {dtype}\")\n",
    "        \n",
    "        # Calculate the new transform and dimensions for the target extent\n",
    "        #new_transform = Affine(target_resolution, 0, target_extent.left, 0, -target_resolution, target_extent.top)\n",
    "        src_extent = src.bounds\n",
    "        new_transform = Affine(target_resolution, 0, src_extent.left, 0, -target_resolution, src_extent.top)\n",
    "        new_width = int((target_extent.right - target_extent.left) / target_resolution)\n",
    "        new_height = int((target_extent.top - target_extent.bottom) / target_resolution)\n",
    "        \n",
    "        # Read the data, resampling and clipping as necessary\n",
    "        window = from_bounds(*target_extent, transform=src.transform)\n",
    "        data = src.read(\n",
    "            out_shape=(src.count, new_height, new_width),\n",
    "            window=window,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        \n",
    "        # Update metadata\n",
    "        profile = src.profile\n",
    "        profile.update({\n",
    "            'transform': new_transform,\n",
    "            'width': new_width,\n",
    "            'height': new_height,\n",
    "            'res': (target_resolution, target_resolution),\n",
    "            'dtype': dtype,\n",
    "            'compress': f'{compression}'\n",
    "        })\n",
    "        \n",
    "        # Write the resampled and clipped data to a new file\n",
    "        with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "            dst.write(data.astype(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled raster saved to L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m4.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "\n",
    "# Open the input raster\n",
    "#input_raster_path = 'input_1km.tif'\n",
    "input_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "output_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m4.tif'\n",
    "\n",
    "with rasterio.open(input_raster_path) as src:\n",
    "    # Read the data and metadata from the input raster\n",
    "    data = src.read(1)\n",
    "    transform = src.transform\n",
    "    profile = src.profile\n",
    "\n",
    "    # Calculate new transform and dimensions for 100m resolution\n",
    "    new_transform = rasterio.Affine(transform.a / 10, transform.b, transform.c,\n",
    "                                    transform.d, transform.e / 10, transform.f)\n",
    "    new_height = src.height * 10\n",
    "    new_width = src.width * 10\n",
    "\n",
    "    # Update the profile with new dimensions and transform\n",
    "    profile.update({\n",
    "        'height': new_height,\n",
    "        'width': new_width,\n",
    "        'transform': new_transform,\n",
    "        'compress': 'zstd'\n",
    "    })\n",
    "\n",
    "    # Create a new array with the upsampled data\n",
    "    resampled_data = np.repeat(np.repeat(data, 10, axis=0), 10, axis=1)\n",
    "\n",
    "    # Write the resampled data to a new file\n",
    "    with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(resampled_data, 1)\n",
    "\n",
    "print(f\"Resampled raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale, align EEA refgrid to match fire data extent and resolution\n",
    "input_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "target_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m3.tif'\n",
    "compression = 'zstd'\n",
    "dtype = 'int32'\n",
    "rescale_and_clip_to_target(input_raster_path, target_raster_path, output_raster_path, compression, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_and_clip_to_target2(input_raster_path, target_raster_path, output_raster_path, compression, dtype):\n",
    "    \"\"\"\n",
    "    Rescale a raster to match the resolution and clip it to the extent of another raster.\n",
    "\n",
    "    Parameters:\n",
    "    - input_raster_path: str, path to the input raster file (e.g., 'path/to/input_raster.tif')\n",
    "    - target_raster_path: str, path to the target raster file (e.g., 'path/to/target_raster.tif')\n",
    "    - output_raster_path: str, path to the output raster file (e.g., 'path/to/output_raster.tif')\n",
    "    - compression: str, compression type (e.g., 'zstd', 'deflate', 'lwz')\n",
    "    - dtype: str, output data type (e.g., 'int16')\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(target_raster_path) as target_src:\n",
    "        # Get the extent and resolution of the target raster\n",
    "        target_extent = target_src.bounds\n",
    "        target_resolution = target_src.res[0]  # Assuming square pixels\n",
    "    \n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        # Ensure the data type is the same as the target\n",
    "        if src.dtypes[0] != dtype:\n",
    "            raise ValueError(f\"Input raster is not of type {dtype}\")\n",
    "        \n",
    "        # Calculate the new transform and dimensions for the target extent\n",
    "        new_transform = Affine(target_resolution, 0, target_extent.left, 0, -target_resolution, target_extent.top)\n",
    "        new_width = int((target_extent.right - target_extent.left) / target_resolution)\n",
    "        new_height = int((target_extent.top - target_extent.bottom) / target_resolution)\n",
    "        \n",
    "        # Read the data, resampling and clipping as necessary\n",
    "        window = from_bounds(*target_extent, transform=src.transform)\n",
    "        data = src.read(\n",
    "            out_shape=(src.count, new_height, new_width),\n",
    "            window=window\n",
    "        )\n",
    "        \n",
    "        # Update metadata\n",
    "        profile = src.profile\n",
    "        profile.update({\n",
    "            'transform': new_transform,\n",
    "            'width': new_width,\n",
    "            'height': new_height,\n",
    "            'res': (target_resolution, target_resolution),\n",
    "            'dtype': dtype,\n",
    "            'compress': f'{compression}'\n",
    "        })\n",
    "        \n",
    "        # Write the resampled and clipped data to a new file\n",
    "        with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "            dst.write(data.astype(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale, align EEA refgrid to match fire data extent and resolution\n",
    "input_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "target_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m_tt2.tif'\n",
    "compression = 'zstd'\n",
    "dtype = 'int32'\n",
    "rescale_and_clip_to_target2(input_raster_path, target_raster_path, output_raster_path, compression, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_raster(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = src.read(1)  # Read the first band\n",
    "    return data\n",
    "\n",
    "def compute_pixel_counts(zone_raster, value_raster):\n",
    "    zones = np.unique(zone_raster)\n",
    "    counts = {}\n",
    "    \n",
    "    for zone in zones:\n",
    "        if zone == 0:\n",
    "            continue  # Skip background or no-data zone if present\n",
    "        mask = (zone_raster == zone) & (value_raster != 0)  # Assuming non-zero values are valid\n",
    "        counts[zone] = np.sum(mask)\n",
    "        \n",
    "    return counts\n",
    "\n",
    "# Load rasters\n",
    "zone_raster = load_raster('rescaled_zone_raster.tif')\n",
    "value_raster = load_raster('aligned_value_raster.tif')\n",
    "\n",
    "# Compute pixel counts\n",
    "pixel_counts = compute_pixel_counts(zone_raster, value_raster)\n",
    "print(pixel_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "value_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Paths to input and output files\n",
    "value_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "extent_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = os.path.join(outputFolder, 'devdata', 'grid1KmLAND_v2_enlarged.tif')\n",
    "\n",
    "# Open the value raster\n",
    "with rasterio.open(value_raster_path) as value_raster:\n",
    "    value_data = value_raster.read(1)\n",
    "    value_transform = value_raster.transform\n",
    "    value_crs = value_raster.crs\n",
    "    value_nodata = value_raster.nodata\n",
    "\n",
    "# Open the extent raster\n",
    "with rasterio.open(extent_raster_path) as extent_raster:\n",
    "    extent_transform = extent_raster.transform\n",
    "    extent_crs = extent_raster.crs\n",
    "    extent_width = extent_raster.width\n",
    "    extent_height = extent_raster.height\n",
    "\n",
    "# Initialize the output array with nodata values\n",
    "output_data = np.full((extent_height, extent_width), value_nodata, dtype=value_data.dtype)\n",
    "\n",
    "# Calculate the coordinates of the extent raster\n",
    "extent_bounds = extent_raster.bounds\n",
    "extent_left, extent_bottom = extent_bounds.left, extent_bounds.bottom\n",
    "\n",
    "# Calculate the window of the value raster that fits within the extent raster\n",
    "value_window = rasterio.windows.from_bounds(\n",
    "    left=extent_left, bottom=extent_bottom,\n",
    "    right=extent_bounds.right, top=extent_bounds.top,\n",
    "    transform=value_transform\n",
    ")\n",
    "\n",
    "# Reproject the value raster to match the extent raster\n",
    "reproject(\n",
    "    source=value_data,\n",
    "    destination=output_data,\n",
    "    src_transform=value_transform,\n",
    "    src_crs=value_crs,\n",
    "    dst_transform=extent_transform,\n",
    "    dst_crs=extent_crs,\n",
    "    resampling=Resampling.nearest,\n",
    "    src_nodata=value_nodata,\n",
    "    dst_nodata=0\n",
    ")\n",
    "\n",
    "# Save the output raster\n",
    "with rasterio.open(\n",
    "    output_raster_path, 'w',\n",
    "    driver='GTiff',\n",
    "    height=extent_height,\n",
    "    width=extent_width,\n",
    "    count=1,\n",
    "    dtype=value_data.dtype,\n",
    "    crs=extent_crs,\n",
    "    transform=extent_transform,\n",
    "    nodata=0,\n",
    "    compress='zstd'\n",
    ") as dst:\n",
    "    dst.write(output_data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specify affine transform for numpy arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mmap_blocks(compute_zonal_count, zone_dask_array, value_dask_array, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Persist the output array in memory\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m \u001b[43moutput_dask_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Write the output raster \u001b[39;00m\n\u001b[0;32m     52\u001b[0m profile\u001b[38;5;241m.\u001b[39mupdate(dtype\u001b[38;5;241m=\u001b[39mrasterio\u001b[38;5;241m.\u001b[39mfloat32, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:287\u001b[0m, in \u001b[0;36mDaskMethodsMixin.persist\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpersist\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Persist this dask collection into memory\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into a Dask collection with the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    dask.base.persist\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m persist(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:900\u001b[0m, in \u001b[0;36mpersist\u001b[1;34m(traverse, optimize_graph, scheduler, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m     keys\u001b[38;5;241m.\u001b[39mextend(a_keys)\n\u001b[0;32m    898\u001b[0m     postpersists\u001b[38;5;241m.\u001b[39mappend((rebuild, a_keys, state))\n\u001b[1;32m--> 900\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    901\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, results))\n\u001b[0;32m    902\u001b[0m results2 \u001b[38;5;241m=\u001b[39m [r({k: d[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks}, \u001b[38;5;241m*\u001b[39ms) \u001b[38;5;28;01mfor\u001b[39;00m r, ks, s \u001b[38;5;129;01min\u001b[39;00m postpersists]\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[1;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:149\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36mcompute_zonal_count\u001b[1;34m(zone_chunk, value_chunk)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zone_chunk\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m value_chunk\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 36\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mzonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzone_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m zone_stats \u001b[38;5;241m=\u001b[39m {stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m'\u001b[39m]: stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m stats}\n\u001b[0;32m     38\u001b[0m output_chunk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:36\u001b[0m, in \u001b[0;36mzonal_stats\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzonal_stats\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The primary zonal statistics entry point.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    All arguments are passed directly to ``gen_zonal_stats``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    The only difference is that ``zonal_stats`` will\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    return a list rather than a generator.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen_zonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:161\u001b[0m, in \u001b[0;36mgen_zonal_stats\u001b[1;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, boundless, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `band` to specify band number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    159\u001b[0m     band \u001b[38;5;241m=\u001b[39m band_num\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mRaster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m rast:\n\u001b[0;32m    162\u001b[0m     features_iter \u001b[38;5;241m=\u001b[39m read_features(vectors, layer)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features_iter):\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\io.py:261\u001b[0m, in \u001b[0;36mRaster.__init__\u001b[1;34m(self, raster, affine, nodata, band)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raster, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m affine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecify affine transform for numpy arrays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m raster\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine \u001b[38;5;241m=\u001b[39m affine\n",
      "\u001b[1;31mValueError\u001b[0m: Specify affine transform for numpy arrays"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "\n",
    "# Paths to input and output files\n",
    "zone_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m5.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "value_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = os.path.join(outputFolder, 'devdata', 'zonalstats_rasterio_tt.tif')\n",
    "\n",
    "# Load the zone raster and the value raster\n",
    "with rasterio.open(zone_raster_path) as zone_src:\n",
    "    zone_array = zone_src.read(1)\n",
    "    transform = zone_src.transform\n",
    "    crs = zone_src.crs\n",
    "    profile = zone_src.profile\n",
    "\n",
    "with rasterio.open(value_raster_path) as value_src:\n",
    "    value_array = value_src.read(1)\n",
    "\n",
    "# Convert the arrays to Dask arrays\n",
    "zone_dask_array = da.from_array(zone_array, chunks=(1024, 1024))\n",
    "value_dask_array = da.from_array(value_array, chunks=(1024, 1024))\n",
    "\n",
    "# Function to compute zonal count for a chunk\n",
    "def compute_zonal_count(zone_chunk, value_chunk):\n",
    "    if zone_chunk.size == 0 or value_chunk.size == 0:\n",
    "        return np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    stats = zonal_stats(zone_chunk, value_chunk, stats=\"count\")\n",
    "    zone_stats = {stat['zone']: stat['count'] for stat in stats}\n",
    "    output_chunk = np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    for zone_id, count_value in zone_stats.items():\n",
    "        output_chunk[zone_chunk == zone_id] = count_value\n",
    "    \n",
    "    return output_chunk\n",
    "\n",
    "# Compute the zonal count in parallel\n",
    "output_dask_array = da.map_blocks(compute_zonal_count, zone_dask_array, value_dask_array, dtype=np.float32)\n",
    "\n",
    "# Persist the output array in memory\n",
    "output_dask_array = output_dask_array.persist()\n",
    "\n",
    "# Write the output raster \n",
    "profile.update(dtype=rasterio.float32, count=1, compress='zstd')\n",
    "\n",
    "with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "    with ProgressBar():\n",
    "        for i in range(output_dask_array.shape[0]):\n",
    "            dst.write(output_dask_array[i].compute(), 1)\n",
    "\n",
    "print(f\"Zonal count raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specify affine transform for numpy arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mmap_blocks(compute_zonal_count, zone_dask_array, value_dask_array, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Persist the output array in memory\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m \u001b[43moutput_dask_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Write the output raster\u001b[39;00m\n\u001b[0;32m     54\u001b[0m profile\u001b[38;5;241m.\u001b[39mupdate(dtype\u001b[38;5;241m=\u001b[39mrasterio\u001b[38;5;241m.\u001b[39mfloat32, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlzw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:287\u001b[0m, in \u001b[0;36mDaskMethodsMixin.persist\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpersist\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Persist this dask collection into memory\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into a Dask collection with the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    dask.base.persist\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m persist(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:900\u001b[0m, in \u001b[0;36mpersist\u001b[1;34m(traverse, optimize_graph, scheduler, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m     keys\u001b[38;5;241m.\u001b[39mextend(a_keys)\n\u001b[0;32m    898\u001b[0m     postpersists\u001b[38;5;241m.\u001b[39mappend((rebuild, a_keys, state))\n\u001b[1;32m--> 900\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    901\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, results))\n\u001b[0;32m    902\u001b[0m results2 \u001b[38;5;241m=\u001b[39m [r({k: d[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks}, \u001b[38;5;241m*\u001b[39ms) \u001b[38;5;28;01mfor\u001b[39;00m r, ks, s \u001b[38;5;129;01min\u001b[39;00m postpersists]\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[1;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:149\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "Cell \u001b[1;32mIn[2], line 38\u001b[0m, in \u001b[0;36mcompute_zonal_count\u001b[1;34m(zone_chunk, value_chunk)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Use 'count' statistic to get the number of pixels in each zone\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mzonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzone_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m zone_stats \u001b[38;5;241m=\u001b[39m {stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m'\u001b[39m]: stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m stats}\n\u001b[0;32m     40\u001b[0m output_chunk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:36\u001b[0m, in \u001b[0;36mzonal_stats\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzonal_stats\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The primary zonal statistics entry point.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    All arguments are passed directly to ``gen_zonal_stats``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    The only difference is that ``zonal_stats`` will\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    return a list rather than a generator.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen_zonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:161\u001b[0m, in \u001b[0;36mgen_zonal_stats\u001b[1;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, boundless, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `band` to specify band number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    159\u001b[0m     band \u001b[38;5;241m=\u001b[39m band_num\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mRaster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m rast:\n\u001b[0;32m    162\u001b[0m     features_iter \u001b[38;5;241m=\u001b[39m read_features(vectors, layer)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features_iter):\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\io.py:261\u001b[0m, in \u001b[0;36mRaster.__init__\u001b[1;34m(self, raster, affine, nodata, band)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raster, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m affine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecify affine transform for numpy arrays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m raster\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine \u001b[38;5;241m=\u001b[39m affine\n",
      "\u001b[1;31mValueError\u001b[0m: Specify affine transform for numpy arrays"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Paths to input and output files\n",
    "zone_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m5.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "value_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = os.path.join(outputFolder, 'devdata', 'zonalstats_rasterio_tt.tif')\n",
    "\n",
    "# Load the zone raster and the value raster\n",
    "with rasterio.open(zone_raster_path) as zone_src:\n",
    "    zone_array = zone_src.read(1)\n",
    "    transform = zone_src.transform\n",
    "    crs = zone_src.crs\n",
    "    profile = zone_src.profile\n",
    "\n",
    "with rasterio.open(value_raster_path) as value_src:\n",
    "    value_array = value_src.read(1)\n",
    "\n",
    "# Check if the shapes are identical\n",
    "assert zone_array.shape == value_array.shape, \"Zone and value rasters must have the same shape\"\n",
    "\n",
    "# Convert the arrays to Dask arrays with identical chunk sizes\n",
    "chunks = (1024, 1024)\n",
    "zone_dask_array = da.from_array(zone_array, chunks=chunks)\n",
    "value_dask_array = da.from_array(value_array, chunks=chunks)\n",
    "\n",
    "# Function to compute zonal count for a chunk\n",
    "def compute_zonal_count(zone_chunk, value_chunk):\n",
    "    if zone_chunk.size == 0 or value_chunk.size == 0:\n",
    "        return np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    # Use 'count' statistic to get the number of pixels in each zone\n",
    "    stats = zonal_stats(zone_chunk, value_chunk, stats=\"count\")\n",
    "    zone_stats = {stat['zone']: stat['count'] for stat in stats}\n",
    "    output_chunk = np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    for zone_id, count_value in zone_stats.items():\n",
    "        output_chunk[zone_chunk == zone_id] = count_value\n",
    "    \n",
    "    return output_chunk\n",
    "\n",
    "# Compute the zonal count in parallel\n",
    "output_dask_array = da.map_blocks(compute_zonal_count, zone_dask_array, value_dask_array, dtype=np.float32)\n",
    "\n",
    "# Persist the output array in memory\n",
    "output_dask_array = output_dask_array.persist()\n",
    "\n",
    "# Write the output raster\n",
    "profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "    with ProgressBar():\n",
    "        dst.write(output_dask_array.compute(), 1)\n",
    "\n",
    "print(f\"Zonal count raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mmap_blocks(compute_zonal_count, zone_dask_array, value_dask_array, transform\u001b[38;5;241m=\u001b[39mzone_transform, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Persist the output array in memory\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m output_dask_array \u001b[38;5;241m=\u001b[39m \u001b[43moutput_dask_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Write the output raster\u001b[39;00m\n\u001b[0;32m     82\u001b[0m profile\u001b[38;5;241m.\u001b[39mupdate(dtype\u001b[38;5;241m=\u001b[39mrasterio\u001b[38;5;241m.\u001b[39mfloat32, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlzw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:287\u001b[0m, in \u001b[0;36mDaskMethodsMixin.persist\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpersist\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Persist this dask collection into memory\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into a Dask collection with the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    dask.base.persist\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m persist(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\base.py:900\u001b[0m, in \u001b[0;36mpersist\u001b[1;34m(traverse, optimize_graph, scheduler, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m     keys\u001b[38;5;241m.\u001b[39mextend(a_keys)\n\u001b[0;32m    898\u001b[0m     postpersists\u001b[38;5;241m.\u001b[39mappend((rebuild, a_keys, state))\n\u001b[1;32m--> 900\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    901\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, results))\n\u001b[0;32m    902\u001b[0m results2 \u001b[38;5;241m=\u001b[39m [r({k: d[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks}, \u001b[38;5;241m*\u001b[39ms) \u001b[38;5;28;01mfor\u001b[39;00m r, ks, s \u001b[38;5;129;01min\u001b[39;00m postpersists]\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[1;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:149\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\dask\\utils.py:71\u001b[0m, in \u001b[0;36mapply\u001b[1;34m(func, args, kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a function given its positional and keyword arguments.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03mEquivalent to ``func(*args, **kwargs)``\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m>>> dsk = {'task-name': task}  # adds the task to a low level Dask task graph\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs)\n",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m, in \u001b[0;36mcompute_zonal_count\u001b[1;34m(zone_chunk, value_chunk, transform)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Use 'count' statistic to get the number of pixels in each zone\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mzonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzone_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m zone_stats \u001b[38;5;241m=\u001b[39m {stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m'\u001b[39m]: stat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m stats}\n\u001b[0;32m     68\u001b[0m output_chunk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(zone_chunk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:36\u001b[0m, in \u001b[0;36mzonal_stats\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzonal_stats\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The primary zonal statistics entry point.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    All arguments are passed directly to ``gen_zonal_stats``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    The only difference is that ``zonal_stats`` will\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    return a list rather than a generator.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen_zonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\main.py:163\u001b[0m, in \u001b[0;36mgen_zonal_stats\u001b[1;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, boundless, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Raster(raster, affine, nodata, band) \u001b[38;5;28;01mas\u001b[39;00m rast:\n\u001b[0;32m    162\u001b[0m     features_iter \u001b[38;5;241m=\u001b[39m read_features(vectors, layer)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features_iter):\n\u001b[0;32m    164\u001b[0m         geom \u001b[38;5;241m=\u001b[39m shape(feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m geom\u001b[38;5;241m.\u001b[39mgeom_type:\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\io.py:126\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    123\u001b[0m         features_iter \u001b[38;5;241m=\u001b[39m [parse_feature(mapping)]\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Iterable):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# Iterable of feature-like objects\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     features_iter \u001b[38;5;241m=\u001b[39m (\u001b[43mparse_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m features_iter:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject is not a recognized source of Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ubach\\.conda\\envs\\geospatial_ETC_DI_v4\\lib\\site-packages\\rasterstats\\io.py:81\u001b[0m, in \u001b[0;36mparse_feature\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# geojson-like python mapping\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m geom_types:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrap_geom(obj)\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Paths to input and output files\n",
    "zone_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\devdata\\grid1KmLAND_v2_100m5.tif'\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "value_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = os.path.join(outputFolder, 'devdata', 'zonalstats_rasterio_tt.tif')\n",
    "\n",
    "# Load the zone raster\n",
    "with rasterio.open(zone_raster_path) as zone_src:\n",
    "    zone_array = zone_src.read(1)\n",
    "    zone_transform = zone_src.transform\n",
    "    zone_crs = zone_src.crs\n",
    "    profile = zone_src.profile\n",
    "\n",
    "# Load the value raster and resample it to match the zone raster\n",
    "with rasterio.open(value_raster_path) as value_src:\n",
    "    value_transform = value_src.transform\n",
    "    value_crs = value_src.crs\n",
    "    \n",
    "    # Calculate the transform and shape for the output raster\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        value_crs, zone_crs, value_src.width, value_src.height, *value_src.bounds)\n",
    "    \n",
    "    profile.update({\n",
    "        'crs': zone_crs,\n",
    "        'transform': zone_transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "    \n",
    "    # Create an array for the resampled data\n",
    "    value_resampled = np.empty((height, width), dtype=value_src.meta['dtype'])\n",
    "    \n",
    "    # Reproject and resample the value raster to match the zone raster\n",
    "    reproject(\n",
    "        source=rasterio.band(value_src, 1),\n",
    "        destination=value_resampled,\n",
    "        src_transform=value_transform,\n",
    "        src_crs=value_crs,\n",
    "        dst_transform=zone_transform,\n",
    "        dst_crs=zone_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "\n",
    "# Check if the shapes are identical\n",
    "assert zone_array.shape == value_resampled.shape, \"Zone and value rasters must have the same shape after resampling\"\n",
    "\n",
    "# Convert the arrays to Dask arrays with identical chunk sizes\n",
    "chunks = (1024, 1024)\n",
    "zone_dask_array = da.from_array(zone_array, chunks=chunks)\n",
    "value_dask_array = da.from_array(value_resampled, chunks=chunks)\n",
    "\n",
    "# Function to compute zonal count for a chunk\n",
    "def compute_zonal_count(zone_chunk, value_chunk, transform):\n",
    "    if zone_chunk.size == 0 or value_chunk.size == 0:\n",
    "        return np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    # Use 'count' statistic to get the number of pixels in each zone\n",
    "    stats = zonal_stats(zone_chunk, value_chunk, affine=transform, stats=\"count\")\n",
    "    zone_stats = {stat['zone']: stat['count'] for stat in stats}\n",
    "    output_chunk = np.zeros_like(zone_chunk, dtype=np.float32)\n",
    "    \n",
    "    for zone_id, count_value in zone_stats.items():\n",
    "        output_chunk[zone_chunk == zone_id] = count_value\n",
    "    \n",
    "    return output_chunk\n",
    "\n",
    "# Compute the zonal count in parallel\n",
    "output_dask_array = da.map_blocks(compute_zonal_count, zone_dask_array, value_dask_array, transform=zone_transform, dtype=np.float32)\n",
    "\n",
    "# Persist the output array in memory\n",
    "output_dask_array = output_dask_array.persist()\n",
    "\n",
    "# Write the output raster\n",
    "profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "    with ProgressBar():\n",
    "        dst.write(output_dask_array.compute(), 1)\n",
    "\n",
    "print(f\"Zonal count raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths to input and output files\n",
    "zone_raster_path = zone_raster_path\n",
    "outputFolder = r'L:\\f02_data\\wildfires\\spatial_data\\output'\n",
    "value_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "output_raster_path = os.path.join(outputFolder, devdata, 'zonalstats_rasterio_tt.tif')\n",
    "\n",
    "# Load the zone raster and the value raster\n",
    "with rasterio.open(zone_raster_path) as zone_src:\n",
    "    zone_array = zone_src.read(1)\n",
    "    transform = zone_src.transform\n",
    "    crs = zone_src.crs\n",
    "    profile = zone_src.profile\n",
    "\n",
    "with rasterio.open(value_raster_path) as value_src:\n",
    "    value_array = value_src.read(1)\n",
    "\n",
    "# Compute zonal statistics\n",
    "stats = zonal_stats(zone_array, value_array, stats=\"count\")\n",
    "\n",
    "# Create a dictionary to map zone IDs to their mean values\n",
    "zone_stats = {stat['zone']: stat['count'] for stat in stats}\n",
    "\n",
    "# Create an output array to hold the zonal means\n",
    "output_array = np.zeros_like(zone_array, dtype=np.float32)\n",
    "\n",
    "# Map the computed mean to the corresponding zones in the output array\n",
    "for zone_id, mean_value in zone_stats.items():\n",
    "    output_array[zone_array == zone_id] = mean_value\n",
    "\n",
    "# Update the profile to reflect the data type of the output array\n",
    "profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "# Write the output array to a new raster file\n",
    "with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "    dst.write(output_array, 1)\n",
    "\n",
    "print(f\"Zonal statistics raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Open the rasters\n",
    "with rasterio.open(zone_raster_path) as zone_src:\n",
    "    zone_array = zone_src.read(1)\n",
    "    \n",
    "with rasterio.open(value_raster_path) as value_src:\n",
    "    value_array = value_src.read(1)\n",
    "\n",
    "# Convert to Dask arrays\n",
    "zone_dask_array = da.from_array(zone_array, chunks=(1024, 1024))\n",
    "value_dask_array = da.from_array(value_array, chunks=(1024, 1024))\n",
    "\n",
    "# Function to compute zonal statistics for a chunk\n",
    "def compute_zonal_stats(zone_chunk, value_chunk):\n",
    "    return zonal_stats(zone_chunk, value_chunk, stats=\"count mean sum\")\n",
    "\n",
    "# Map the function across the Dask arrays\n",
    "result = da.map_blocks(compute_zonal_stats, zone_dask_array, value_dask_array, dtype=object).compute()\n",
    "\n",
    "# Collect the results\n",
    "zonal_stats_result = [item for sublist in result for item in sublist]\n",
    "\n",
    "# Print the statistics\n",
    "for stat in zonal_stats_result:\n",
    "    print(stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def load_raster(file_path):\n",
    "    data = rioxarray.open_rasterio(file_path, chunks=True).squeeze()\n",
    "    return data\n",
    "\n",
    "def compute_pixel_counts_dask(zone_raster):\n",
    "    unique_zones = np.unique(zone_raster.compute())\n",
    "    counts = {}\n",
    "    \n",
    "    for zone in unique_zones:\n",
    "        if zone == 0:\n",
    "            continue  # Skip background or no-data zone if present\n",
    "        mask = (zone_raster == zone)\n",
    "        counts[zone] = mask.sum().compute()\n",
    "        \n",
    "    return counts\n",
    "\n",
    "def create_count_raster_dask(zone_raster, counts, profile, output_path):\n",
    "    count_raster = da.map_blocks(lambda block: np.vectorize(counts.get)(block), zone_raster, dtype=np.uint32)\n",
    "    count_raster = count_raster.compute()\n",
    "\n",
    "    profile.update(dtype=rasterio.uint32, count=1)\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(count_raster, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rasters\n",
    "zone_raster = load_raster('rescaled_zone_raster.tif')\n",
    "\n",
    "# Compute pixel counts\n",
    "counts = compute_pixel_counts_dask(zone_raster)\n",
    "\n",
    "# Prepare profile\n",
    "with rasterio.open('rescaled_zone_raster.tif') as src:\n",
    "    profile = src.profile\n",
    "\n",
    "# Create and save the count raster\n",
    "create_count_raster_dask(zone_raster.data, counts, profile, 'output_count_raster.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def load_raster(file_path):\n",
    "    data = rioxarray.open_rasterio(file_path, chunks=True).squeeze()\n",
    "    return data\n",
    "\n",
    "def compute_pixel_counts_dask(zone_raster):\n",
    "    unique_zones = np.unique(zone_raster.compute())\n",
    "    counts = {}\n",
    "    \n",
    "    for zone in unique_zones:\n",
    "        if zone == 0:\n",
    "            continue  # Skip background or no-data zone if present\n",
    "        mask = (zone_raster == zone)\n",
    "        counts[zone] = mask.sum().compute()\n",
    "        \n",
    "    return counts\n",
    "\n",
    "def create_count_raster_dask(zone_raster, counts, profile, output_path):\n",
    "    count_raster = da.map_blocks(lambda block: np.vectorize(counts.get)(block), zone_raster, dtype=np.uint32)\n",
    "    count_raster = count_raster.compute()\n",
    "\n",
    "    profile.update(dtype=rasterio.uint32, count=1)\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(count_raster, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rasters\n",
    "zone_raster = load_raster(zone_raster_path)\n",
    "\n",
    "# Compute pixel counts\n",
    "counts = compute_pixel_counts_dask(zone_raster)\n",
    "\n",
    "# Prepare profile\n",
    "with rasterio.open(zone_raster_path) as src:\n",
    "    profile = src.profile\n",
    "\n",
    "# Create and save the count raster\n",
    "create_count_raster_dask(zone_raster.data, counts, profile, 'output_count_raster.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 63727 , height: 54633\n"
     ]
    }
   ],
   "source": [
    "target_raster_path = os.path.join(outputFolder, 'FIRE_ID', 'FIREID_2000.tif')\n",
    "with rasterio.open(target_raster_path) as target_src:\n",
    "    # Get the extent and resolution of the target raster\n",
    "    target_extent = target_src.bounds\n",
    "    target_resolution = target_src.res[0]  # Assuming square pixels\n",
    "    new_transform = Affine(target_resolution, 0, target_extent.left, 0, -target_resolution, target_extent.top)\n",
    "    new_width = int((target_extent.right - target_extent.left) / target_resolution)\n",
    "    new_height = int((target_extent.top - target_extent.bottom) / target_resolution)\n",
    "    print(f'width: {new_width} , height: {new_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=943900.0, bottom=941700.0, right=7316600.0, top=6405000.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_src.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_src.res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the new transform and dimensions for the target extent\n",
    "new_transform = Affine(target_resolution, 0, target_extent.left, 0, -target_resolution, target_extent.top)\n",
    "new_width = int((target_extent.right - target_extent.left) / target_resolution)\n",
    "new_height = int((target_extent.top - target_extent.bottom) / target_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(1000.0, 0.0, 943000.0,\n",
       "       0.0, -1000.0, 5416000.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 6374 , height: 4475\n"
     ]
    }
   ],
   "source": [
    "print(f'width: {new_width} , height: {new_height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 6374 , height: 4475\n"
     ]
    }
   ],
   "source": [
    "input_raster_path = r'L:\\f02_data\\wildfires\\spatial_data\\input\\grid1KmLAND_v2.tif'\n",
    "with rasterio.open(input_raster_path) as input_src:\n",
    "    # Get the extent and resolution of the target raster\n",
    "    input_src_extent = input_src.bounds\n",
    "    input_src_resolution = input_src.res[0]  # Assuming square pixels\n",
    "\n",
    "width = int((input_src_extent.right - input_src_extent.left) / input_src_resolution)\n",
    "height = int((input_src_extent.top - input_src_extent.bottom) / input_src_resolution)\n",
    "print(f'width: {width} , height: {height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundingBox(left=943000.0, bottom=941000.0, right=7317000.0, top=5416000.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_src.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_src.res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_raster(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = src.read(1)  # Read the first band\n",
    "    return data\n",
    "\n",
    "def compute_pixel_counts(zone_raster, value_raster):\n",
    "    zones = np.unique(zone_raster)\n",
    "    counts = {}\n",
    "    \n",
    "    for zone in zones:\n",
    "        if zone == 0:\n",
    "            continue  # Skip background or no-data zone if present\n",
    "        mask = (zone_raster == zone) & (value_raster != 0)  # Assuming non-zero values are valid\n",
    "        counts[zone] = np.sum(mask)\n",
    "        \n",
    "    return counts\n",
    "\n",
    "# Load rasters\n",
    "zone_raster = load_raster('rescaled_zone_raster.tif')\n",
    "value_raster = load_raster('aligned_value_raster.tif')\n",
    "\n",
    "# Compute pixel counts\n",
    "pixel_counts = compute_pixel_counts(zone_raster, value_raster)\n",
    "print(pixel_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_ETC_DI_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
